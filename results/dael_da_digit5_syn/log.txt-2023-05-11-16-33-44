***************
** Arguments **
***************
backbone: 
config_file: configs/trainers/da/dael/digit5.yaml
dataset_config_file: configs/datasets/da/digit5.yaml
eval_only: False
head: 
load_epoch: None
model_dir: 
no_train: False
opts: []
output_dir: output/source_only_digit5
resume: 
root: raw_datasets
seed: -1
source_domains: ['mnist', 'mnist_m', 'svhn', 'usps']
target_domains: ['syn']
trainer: DAEL
transforms: None
************
** Config **
************
DATALOADER:
  K_TRANSFORMS: 1
  NUM_WORKERS: 4
  RETURN_IMG0: False
  TEST:
    BATCH_SIZE: 256
    SAMPLER: SequentialSampler
  TRAIN_U:
    BATCH_SIZE: 64
    N_DOMAIN: 0
    N_INS: 16
    SAME_AS_X: False
    SAMPLER: RandomSampler
  TRAIN_X:
    BATCH_SIZE: 256
    N_DOMAIN: 0
    N_INS: 16
    SAMPLER: RandomDomainSampler
DATASET:
  ALL_AS_UNLABELED: False
  CIFAR_C_LEVEL: 1
  CIFAR_C_TYPE: 
  NAME: Digit5
  NUM_LABELED: -1
  NUM_SHOTS: -1
  ROOT: raw_datasets
  SOURCE_DOMAINS: ['mnist', 'mnist_m', 'svhn', 'usps']
  STL10_FOLD: -1
  TARGET_DOMAINS: ['syn']
  VAL_PERCENT: 0.1
INPUT:
  COLORJITTER_B: 0.4
  COLORJITTER_C: 0.4
  COLORJITTER_H: 0.1
  COLORJITTER_S: 0.4
  CROP_PADDING: 4
  CUTOUT_LEN: 16
  CUTOUT_N: 1
  GB_K: 21
  GB_P: 0.5
  GN_MEAN: 0.0
  GN_STD: 0.15
  INTERPOLATION: bilinear
  NO_TRANSFORM: False
  PIXEL_MEAN: [0.5, 0.5, 0.5]
  PIXEL_STD: [0.5, 0.5, 0.5]
  RANDAUGMENT_M: 10
  RANDAUGMENT_N: 2
  RGS_P: 0.2
  RRCROP_SCALE: (0.08, 1.0)
  SIZE: (32, 32)
  TRANSFORMS: ('normalize',)
MODEL:
  BACKBONE:
    NAME: cnn_digit5_m3sda
    PRETRAINED: True
  HEAD:
    ACTIVATION: relu
    BN: True
    DROPOUT: 0.0
    HIDDEN_LAYERS: ()
    NAME: 
  INIT_WEIGHTS: 
OPTIM:
  ADAM_BETA1: 0.9
  ADAM_BETA2: 0.999
  BASE_LR_MULT: 0.1
  GAMMA: 0.1
  LR: 0.05
  LR_SCHEDULER: cosine
  MAX_EPOCH: 10
  MOMENTUM: 0.9
  NAME: sgd
  NEW_LAYERS: ()
  RMSPROP_ALPHA: 0.99
  SGD_DAMPNING: 0
  SGD_NESTEROV: False
  STAGED_LR: False
  STEPSIZE: (30,)
  WARMUP_CONS_LR: 1e-05
  WARMUP_EPOCH: -1
  WARMUP_MIN_LR: 1e-05
  WARMUP_RECOUNT: True
  WARMUP_TYPE: linear
  WEIGHT_DECAY: 0.0005
OUTPUT_DIR: output/source_only_digit5
RESUME: 
SEED: -1
TEST:
  COMPUTE_CMAT: False
  EVALUATOR: Classification
  FINAL_MODEL: last_step
  NO_TEST: False
  PER_CLASS_RESULT: False
  SPLIT: test
TRAIN:
  CHECKPOINT_FREQ: 0
  COUNT_ITER: train_x
  PRINT_FREQ: 10
TRAINER:
  DAEL:
    CONF_THRE: 0.95
    STRONG_TRANSFORMS: ('randaugment2', 'normalize')
    WEIGHT_U: 0.5
  NAME: DAEL
USE_CUDA: True
VERBOSE: True
VERSION: 1
Collecting env info ...
** System info **
PyTorch version: 2.0.1
Is debug build: False
CUDA used to build PyTorch: Could not collect
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.3 LTS (x86_64)
GCC version: (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
Clang version: Could not collect
CMake version: version 3.26.3
Libc version: glibc-2.31

Python version: 3.8.16 | packaged by conda-forge | (default, Feb  1 2023, 16:01:55)  [GCC 11.3.0] (64-bit runtime)
Python platform: Linux-5.15.0-56-generic-x86_64-with-glibc2.10
Is CUDA available: False
CUDA runtime version: 11.4.152
CUDA_MODULE_LOADING set to: N/A
GPU models and configuration: GPU 0: NVIDIA A40
Nvidia driver version: 525.105.17
cuDNN version: Probably one of the following:
/usr/lib/x86_64-linux-gnu/libcudnn.so.8.2.4
/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.2.4
/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.2.4
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.2.4
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.2.4
/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.2.4
/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.2.4
HIP runtime version: N/A
MIOpen runtime version: N/A
Is XNNPACK available: True

CPU:
Architecture:                    x86_64
CPU op-mode(s):                  32-bit, 64-bit
Byte Order:                      Little Endian
Address sizes:                   48 bits physical, 48 bits virtual
CPU(s):                          128
On-line CPU(s) list:             0-127
Thread(s) per core:              2
Core(s) per socket:              32
Socket(s):                       2
NUMA node(s):                    8
Vendor ID:                       AuthenticAMD
CPU family:                      25
Model:                           1
Model name:                      AMD EPYC 7543 32-Core Processor
Stepping:                        1
Frequency boost:                 enabled
CPU MHz:                         1500.000
CPU max MHz:                     2800.0000
CPU min MHz:                     1500.0000
BogoMIPS:                        5589.56
Virtualization:                  AMD-V
L1d cache:                       2 MiB
L1i cache:                       2 MiB
L2 cache:                        32 MiB
L3 cache:                        512 MiB
NUMA node0 CPU(s):               0-7,64-71
NUMA node1 CPU(s):               8-15,72-79
NUMA node2 CPU(s):               16-23,80-87
NUMA node3 CPU(s):               24-31,88-95
NUMA node4 CPU(s):               32-39,96-103
NUMA node5 CPU(s):               40-47,104-111
NUMA node6 CPU(s):               48-55,112-119
NUMA node7 CPU(s):               56-63,120-127
Vulnerability Itlb multihit:     Not affected
Vulnerability L1tf:              Not affected
Vulnerability Mds:               Not affected
Vulnerability Meltdown:          Not affected
Vulnerability Mmio stale data:   Not affected
Vulnerability Retbleed:          Not affected
Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl and seccomp
Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization
Vulnerability Spectre v2:        Mitigation; Retpolines, IBPB conditional, IBRS_FW, STIBP always-on, RSB filling, PBRSB-eIBRS Not affected
Vulnerability Srbds:             Not affected
Vulnerability Tsx async abort:   Not affected
Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl nonstop_tsc cpuid extd_apicid aperfmperf rapl pni pclmulqdq monitor ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand lahf_lm cmp_legacy svm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw ibs skinit wdt tce topoext perfctr_core perfctr_nb bpext perfctr_llc mwaitx cpb cat_l3 cdp_l3 invpcid_single hw_pstate ssbd mba ibrs ibpb stibp vmmcall fsgsbase bmi1 avx2 smep bmi2 invpcid cqm rdt_a rdseed adx smap clflushopt clwb sha_ni xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local clzero irperf xsaveerptr rdpru wbnoinvd amd_ppin arat npt lbrv svm_lock nrip_save tsc_scale vmcb_clean flushbyasid decodeassists pausefilter pfthreshold v_vmsave_vmload vgif v_spec_ctrl umip pku ospke vaes vpclmulqdq rdpid overflow_recov succor smca

Versions of relevant libraries:
[pip3] numpy==1.24.3
[pip3] torch==2.0.1
[pip3] torchvision==0.15.2
[conda] blas                      2.106                       mkl    conda-forge
[conda] cudatoolkit               10.2.89             h713d32c_11    conda-forge
[conda] libblas                   3.9.0                     6_mkl    conda-forge
[conda] libcblas                  3.9.0                     6_mkl    conda-forge
[conda] liblapack                 3.9.0                     6_mkl    conda-forge
[conda] liblapacke                3.9.0                     6_mkl    conda-forge
[conda] mkl                       2020.4             h726a3e6_304    conda-forge
[conda] numpy                     1.24.3           py38h59b608b_0    conda-forge
[conda] pytorch                   2.0.1               py3.8_cpu_0    pytorch
[conda] pytorch-mutex             1.0                         cpu    pytorch
[conda] torchvision               0.15.2                 py38_cpu    pytorch
        Pillow (9.4.0)

Loading trainer: DAEL
Building transform_train
+ resize to 32x32
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
Building transform_train
+ resize to 32x32
+ randaugment2 (n=2)
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
Loading dataset: Digit5
* Using custom transform for training
Building transform_test
+ resize the smaller edge to 32
+ 32x32 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
---------  ------------------------------------
Dataset    Digit5
Source     ['mnist', 'mnist_m', 'svhn', 'usps']
Target     ['syn']
# classes  10
# train_x  97,314
# train_u  25,000
# test     9,000
---------  ------------------------------------
Building F
Backbone: cnn_digit5_m3sda
# params: 31,785,408
Building E
# params: 81,960
Loading evaluator: Classification
Found checkpoint at output/source_only_digit5 (will resume training)
Loading checkpoint from "output/source_only_digit5/F/model.pth.tar-10"
Loaded model weights
Loaded optimizer
Loaded scheduler
Previous epoch: 10
Loading checkpoint from "output/source_only_digit5/E/model.pth.tar-10"
Loaded model weights
Loaded optimizer
Loaded scheduler
Previous epoch: 10
Initialize tensorboard (log_dir=output/source_only_digit5/tensorboard)
Finish training
Deploy the last-epoch model
Evaluate on the *test* set
=> result
* total: 9,000
* correct: 8,719
* accuracy: 96.9%
* error: 3.1%
* macro_f1: 96.9%
Elapsed: 0:00:06
